
# 【初級】AWSで構築するデータレイク基盤概要とアーキテクチャ例のご紹介


## 目次
---

* データレイクとは
* aws で構築するデータレイク基盤
* awsのデータレイク事例
* aws lake formation が異様

### データレイクとは

↓ウィキを意訳  

企業では想像する以上のデータを抱えており、あるリサーチ会社のデータによると、データの量は5年で10倍以上に増えるが、データの保管期間は15年と比較的長い。  
そんな大量のデータを保管するための基盤としてデータレイクが存在する。  
データレイクは通常のデータストアと下記の点で大きく異なる。  

システムからの生データのコピー、レポート、可視化、分析、機械学習などで利用するために変換したデータを保管するシングルデータストア  
構造データ、半構造データ(csv, json...)、非構造データ(Eメール、PDF...)、バイナリデータを保管可能  


## 論理的推論の２つの手法
---

### 演繹法(ボトムアップ)  

一般論やルールに観察事項を加えて必然的な結論を導く思考方法  
ex) 「人間はいつか死ぬ」 -> 「ソクラテスは人間である」 -> 「ソクラテスはいつか死ぬ(結論)」  

### 帰納法(ボトムダウン)  

多くの観察軸から類似点をまとめ上げることで結論を出す思考方法  
ex) 「人であるソクラテスは死んだ」、「人であるプラトンは死んだ」、「人であるアリストテレスは死んだ」 -> 「したがって人はいつか死ぬ(結論)」  


## ビックデータ分析基盤
---
データレイクとデータウェアハウスを用いて分析用のアーキテクチャを構築する必要がある。
データレイク基盤としてS3やGlue、データウェアハウスとしてRedshiftなどのAWSサービスを活用することでフルマネージドなビックデータ分析基盤を作り上げられる。

* S3  
  S3はデータレイクに最適なストレージ  
  （事前容量確保不要）
  大容量でも安価
* AWS Glue  
  データレイクのデータカタログ(データの構造(列、型…)、アクセス方法を定義して他機能からの検索を可能にするもの)とETL処理をおこなう  
  AWS Glueデータカタログ
* Amazon Redshift  
  フルマネージドのクラウド型データウェアハウスサービス
* Redshift Spectrum  
  Redshiftが拡張されてS3上に置いたファイルを外部デーブルとして直接参照して分析処理が可能


## データレイクとデータウェアハウスの連携
---

* データレイクにデータを投入する
* データの構造化を行い、DWHに投入する
* データウェアハウスでの古くなったが保存したいデータをデータレイクに再度移動してアーカイブする


## ビッグデータの処理
---

* Amazon Elastic MapReduce(EMR)  
  Hadoop/Sparkなどの大規模分散処理環境のマネージドサービス。簡単にクラスタの構築が可能。  
  S3との連携が可能で、EMRFSを使用すると、S3をHDFSのように扱うことが可能になる。  
    
    例：s3//:xxxxde
    ⇒アクセスできる

    そのことで下記のようなことが実現できる  

    * 計算ノードとストレージの分離
    * クラスタのシャットダウン
    * 複数クラスタ間でのデータ共有
    * データの耐久性の向上

* Amazon Athena  
  S3に保存した半構造ファイル(csv, tsv)をSQLを用いて分析できる

## データレイク事例
amazonの事例  
出荷倉庫で日々集まるデータを収集し、分析する基盤をAWS上でAmazon.comが構築している。  
データレイクがなかった頃は50PBのデータを600,000分析ジョブを用いて分析していた。  
しかしそれ以上の量のデータを分析し、分析事項も増やしたかったためS3にデータレイクを作成し、Redshift、Spectrum、EMRを用いたソリューションを構築した。  
付加価値としてコストが1/2に減った。

## AWS lake formation(プレビュー中)
データレイクのサービス  
今までよりも早くデータレイクを作れる（数日）  
まだプレビュー中のサービス  
